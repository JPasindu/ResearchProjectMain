{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b52b1ef-4ead-4003-84cd-bed87e4470aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: results_txt/n=200_pi1=0.4_pi2=0.4.txt\n",
      "Processed: results_txt/n=1000_pi1=0.2_pi2=0.2.txt\n",
      "Processed: results_txt/n=10000_pi1=0.3_pi2=0.3.txt\n",
      "Processed: results_txt/n=2000_pi1=0.2_pi2=0.2.txt\n",
      "Processed: results_txt/n=5000_pi1=0.2_pi2=0.2.txt\n",
      "Processed: results_txt/n=500_pi1=0.3_pi2=0.3.txt\n",
      "Processed: results_txt/n=50_pi1=0.3_pi2=0.3.txt\n",
      "Processed: results_txt/n=2000_pi1=0.4_pi2=0.4.txt\n",
      "Processed: results_txt/n=5000_pi1=0.4_pi2=0.4.txt\n",
      "Processed: results_txt/n=100_pi1=0.3_pi2=0.3.txt\n",
      "Processed: results_txt/n=200_pi1=0.2_pi2=0.2.txt\n",
      "Processed: results_txt/n=1000_pi1=0.4_pi2=0.4.txt\n",
      "Processed: results_txt/n=500_pi1=0.2_pi2=0.2.txt\n",
      "Processed: results_txt/n=5000_pi1=0.3_pi2=0.3.txt\n",
      "Processed: results_txt/n=50_pi1=0.2_pi2=0.2.txt\n",
      "Processed: results_txt/n=2000_pi1=0.3_pi2=0.3.txt\n",
      "Processed: results_txt/n=1000_pi1=0.3_pi2=0.3.txt\n",
      "Processed: results_txt/n=10000_pi1=0.2_pi2=0.2.txt\n",
      "Processed: results_txt/n=100_pi1=0.4_pi2=0.4.txt\n",
      "Processed: results_txt/n=10000_pi1=0.4_pi2=0.4.txt\n",
      "Processed: results_txt/n=100_pi1=0.2_pi2=0.2.txt\n",
      "Processed: results_txt/n=200_pi1=0.3_pi2=0.3.txt\n",
      "Processed: results_txt/n=50_pi1=0.4_pi2=0.4.txt\n",
      "Processed: results_txt/n=500_pi1=0.4_pi2=0.4.txt\n",
      "\n",
      "Saved summary with 96 model entries to summary.csv\n",
      "\n",
      "Sample verification (showing first 2 experiments):\n",
      "             unique_id    n pi1 pi2                         model                       file  rate_MSE  rate_MAE  rate_R2  count_MSE  count_MAE  count_R2  count_Accuracy\n",
      " n=200_pi1=0.4_pi2=0.4  200 0.4 0.4                  ZKIPModel_EM  n=200_pi1=0.4_pi2=0.4.txt    2.2196    1.3314   0.0135      4.500      4.500   -1.0000          0.4500\n",
      " n=200_pi1=0.4_pi2=0.4  200 0.4 0.4                        ZkICMP  n=200_pi1=0.4_pi2=0.4.txt    2.3447    1.2712  -0.0421      4.500      1.500   -1.0000          0.4500\n",
      " n=200_pi1=0.4_pi2=0.4  200 0.4 0.4 HistGradientBoostingRegressor  n=200_pi1=0.4_pi2=0.4.txt    2.3024    1.3226  -0.0233      2.525      1.375   -0.1222          0.1111\n",
      " n=200_pi1=0.4_pi2=0.4  200 0.4 0.4  PoissonRandomForestRegressor  n=200_pi1=0.4_pi2=0.4.txt    4.0398    1.6401  -0.7955      4.250      1.700   -0.8889          0.1000\n",
      "n=1000_pi1=0.2_pi2=0.2 1000 0.2 0.2                  ZKIPModel_EM n=1000_pi1=0.2_pi2=0.2.txt    3.1123    1.3611   0.3541      5.135      5.135   -0.0657          0.3550\n",
      "n=1000_pi1=0.2_pi2=0.2 1000 0.2 0.2                        ZkICMP n=1000_pi1=0.2_pi2=0.2.txt    4.1730    1.4783   0.1339      5.120      1.470   -0.0626          0.3800\n",
      "n=1000_pi1=0.2_pi2=0.2 1000 0.2 0.2 HistGradientBoostingRegressor n=1000_pi1=0.2_pi2=0.2.txt    3.9131    1.4179   0.1879      3.945      1.385    0.1813          0.2987\n",
      "n=1000_pi1=0.2_pi2=0.2 1000 0.2 0.2  PoissonRandomForestRegressor n=1000_pi1=0.2_pi2=0.2.txt    3.7119    1.4010   0.2296      3.765      1.385    0.2186          0.2400\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def parse_targeted_files_corrected():\n",
    "    \"\"\"Corrected parser with specific path\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # SPECIFY YOUR PATH HERE\n",
    "    target_directory = \"results_txt\"  # Change this to your folder name\n",
    "    # target_directory = \"experiments/data\"  # For nested folders\n",
    "    # target_directory = \"../results\"  # For parent directory\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(target_directory):\n",
    "        print(f\"Error: Directory '{target_directory}' does not exist!\")\n",
    "        return\n",
    "    \n",
    "    # Look for files in the specific directory\n",
    "    for filename in os.listdir(target_directory):\n",
    "        filepath = os.path.join(target_directory, filename)\n",
    "        \n",
    "        # Check if it's a file (not directory) and matches our pattern\n",
    "        if os.path.isfile(filepath) and (any(x in filename for x in ['n=', 'pi1=', 'pi2=']) or filename.endswith('.log') or filename.endswith('.txt')):\n",
    "            try:\n",
    "                with open(filepath, 'r') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                # Extract parameters\n",
    "                n = re.search(r'n=(\\d+)', content)\n",
    "                pi1 = re.search(r'pi1=([\\d.]+)', content)\n",
    "                pi2 = re.search(r'pi2=([\\d.]+)', content)\n",
    "                \n",
    "                if n and pi1 and pi2:\n",
    "                    unique_id = f\"n={n.group(1)}_pi1={pi1.group(1)}_pi2={pi2.group(1)}\"\n",
    "                    \n",
    "                    # Parse metrics for each model\n",
    "                    models_data = parse_all_models_corrected(content, unique_id, n.group(1), pi1.group(1), pi2.group(1), filename)\n",
    "                    all_results.extend(models_data)\n",
    "                    \n",
    "                    print(f\"Processed: {filepath}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error with {filepath}: {e}\")\n",
    "    \n",
    "    # Create and save summary\n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Reorder columns for better readability\n",
    "        column_order = ['unique_id', 'n', 'pi1', 'pi2', 'model', 'file', \n",
    "                       'rate_MSE', 'rate_MAE', 'rate_R2',\n",
    "                       'count_MSE', 'count_MAE', 'count_R2', 'count_Accuracy']\n",
    "        \n",
    "        # Only include columns that actually exist in the data\n",
    "        final_columns = [col for col in column_order if col in df.columns]\n",
    "        df = df[final_columns]\n",
    "        \n",
    "        df.to_csv('summary.csv', index=False)\n",
    "        print(f\"\\nSaved summary with {len(all_results)} model entries to summary.csv\")\n",
    "        \n",
    "        # Display sample to verify no duplicates\n",
    "        print(\"\\nSample verification (showing first 2 experiments):\")\n",
    "        sample_df = df[df['unique_id'].isin(df['unique_id'].unique()[:2])]\n",
    "        print(sample_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No files processed!\")\n",
    "\n",
    "def parse_all_models_corrected(content, unique_id, n, pi1, pi2, filename):\n",
    "    \"\"\"Parse metrics for all models with corrected parsing\"\"\"\n",
    "    models_data = []\n",
    "    \n",
    "    # Parse ZKIPModel_EM\n",
    "    zkip_data = parse_zkp_model_corrected(content, unique_id, n, pi1, pi2, filename)\n",
    "    if zkip_data:\n",
    "        models_data.append(zkip_data)\n",
    "    \n",
    "    # Parse ZkICMP\n",
    "    zkicmp_data = parse_zkicmp_model_corrected(content, unique_id, n, pi1, pi2, filename)\n",
    "    if zkicmp_data:\n",
    "        models_data.append(zkicmp_data)\n",
    "    \n",
    "    # Parse HistGradientBoostingRegressor\n",
    "    hgb_data = parse_hgb_model_corrected(content, unique_id, n, pi1, pi2, filename)\n",
    "    if hgb_data:\n",
    "        models_data.append(hgb_data)\n",
    "    \n",
    "    # Parse PoissonRandomForestRegressor\n",
    "    prf_data = parse_prf_model_corrected(content, unique_id, n, pi1, pi2, filename)\n",
    "    if prf_data:\n",
    "        models_data.append(prf_data)\n",
    "    \n",
    "    return models_data\n",
    "\n",
    "def parse_zkp_model_corrected(content, unique_id, n, pi1, pi2, filename):\n",
    "    \"\"\"Parse ZKIPModel_EM metrics with corrected parsing\"\"\"\n",
    "    if 'ZKIPModel_EM' not in content:\n",
    "        return None\n",
    "    \n",
    "    model_data = {\n",
    "        'unique_id': unique_id,\n",
    "        'n': n,\n",
    "        'pi1': pi1,\n",
    "        'pi2': pi2,\n",
    "        'model': 'ZKIPModel_EM',\n",
    "        'file': filename\n",
    "    }\n",
    "    \n",
    "    # Extract ZKIPModel_EM section\n",
    "    zkip_section = re.search(r'ZKIPModel_EM.*?------------------------------(.*?)(?=------------------------------|$)', content, re.DOTALL)\n",
    "    if zkip_section:\n",
    "        section_content = zkip_section.group(1)\n",
    "        \n",
    "        # Expected value predictions\n",
    "        expected_section = re.search(r'Expected value prediction:(.*?)Mode prediction:', section_content, re.DOTALL)\n",
    "        if expected_section:\n",
    "            expected_text = expected_section.group(1)\n",
    "            model_data['rate_MSE'] = extract_metric_specific(expected_text, 'MSE')\n",
    "            model_data['rate_MAE'] = extract_metric_specific(expected_text, 'MAE')\n",
    "            model_data['rate_R2'] = extract_metric_specific(expected_text, 'r\\^2')\n",
    "        \n",
    "        # Mode predictions\n",
    "        mode_section = re.search(r'Mode prediction:(.*?)(?=Performance metrics:|$)', section_content, re.DOTALL)\n",
    "        if mode_section:\n",
    "            mode_text = mode_section.group(1)\n",
    "            model_data['count_MSE'] = extract_metric_specific(mode_text, 'MSE')\n",
    "            model_data['count_MAE'] = extract_metric_specific(mode_text, 'MAE')\n",
    "            model_data['count_R2'] = extract_metric_specific(mode_text, 'r\\^2')\n",
    "            model_data['count_Accuracy'] = extract_metric_specific(mode_text, 'Accuracy')\n",
    "    \n",
    "    return model_data\n",
    "\n",
    "def parse_zkicmp_model_corrected(content, unique_id, n, pi1, pi2, filename):\n",
    "    \"\"\"Parse ZkICMP metrics with corrected parsing\"\"\"\n",
    "    if 'ZkICMP' not in content:\n",
    "        return None\n",
    "    \n",
    "    model_data = {\n",
    "        'unique_id': unique_id,\n",
    "        'n': n,\n",
    "        'pi1': pi1,\n",
    "        'pi2': pi2,\n",
    "        'model': 'ZkICMP',\n",
    "        'file': filename\n",
    "    }\n",
    "    \n",
    "    # Extract ZkICMP section\n",
    "    zkicmp_section = re.search(r'ZkICMP.*?------------------------------(.*?)(?=------------------------------|$)', content, re.DOTALL)\n",
    "    if zkicmp_section:\n",
    "        section_content = zkicmp_section.group(1)\n",
    "        \n",
    "        # Rate predictions\n",
    "        rate_match = re.search(r'Rate predictions.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?r\\^2:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if rate_match:\n",
    "            model_data['rate_MSE'] = float(rate_match.group(1))\n",
    "            model_data['rate_MAE'] = float(rate_match.group(2))\n",
    "            model_data['rate_R2'] = float(rate_match.group(3))\n",
    "        \n",
    "        # Count predictions\n",
    "        count_match = re.search(r'Count predictions:.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?r\\^2:\\s*([\\d.-]+).*?Accuracy:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if count_match:\n",
    "            model_data['count_MSE'] = float(count_match.group(1))\n",
    "            model_data['count_MAE'] = float(count_match.group(2))\n",
    "            model_data['count_R2'] = float(count_match.group(3))\n",
    "            model_data['count_Accuracy'] = float(count_match.group(4))\n",
    "    \n",
    "    return model_data\n",
    "\n",
    "def parse_hgb_model_corrected(content, unique_id, n, pi1, pi2, filename):\n",
    "    \"\"\"Parse HistGradientBoostingRegressor metrics with corrected parsing\"\"\"\n",
    "    if 'HistGradientBoostingRegressor' not in content:\n",
    "        return None\n",
    "    \n",
    "    model_data = {\n",
    "        'unique_id': unique_id,\n",
    "        'n': n,\n",
    "        'pi1': pi1,\n",
    "        'pi2': pi2,\n",
    "        'model': 'HistGradientBoostingRegressor',\n",
    "        'file': filename\n",
    "    }\n",
    "    \n",
    "    # Extract HistGradientBoostingRegressor section\n",
    "    hgb_section = re.search(r'HistGradientBoostingRegressor.*?------------------------------(.*?)(?=------------------------------|$)', content, re.DOTALL)\n",
    "    if hgb_section:\n",
    "        section_content = hgb_section.group(1)\n",
    "        \n",
    "        # Rate predictions\n",
    "        rate_match = re.search(r'Rate predictions.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?R²:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if rate_match:\n",
    "            model_data['rate_MSE'] = float(rate_match.group(1))\n",
    "            model_data['rate_MAE'] = float(rate_match.group(2))\n",
    "            model_data['rate_R2'] = float(rate_match.group(3))\n",
    "        \n",
    "        # Count predictions\n",
    "        count_match = re.search(r'Count predictions.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?R²:\\s*([\\d.-]+).*?Accuracy:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if count_match:\n",
    "            model_data['count_MSE'] = float(count_match.group(1))\n",
    "            model_data['count_MAE'] = float(count_match.group(2))\n",
    "            model_data['count_R2'] = float(count_match.group(3))\n",
    "            model_data['count_Accuracy'] = float(count_match.group(4))\n",
    "    \n",
    "    return model_data\n",
    "\n",
    "def parse_prf_model_corrected(content, unique_id, n, pi1, pi2, filename):\n",
    "    \"\"\"Parse PoissonRandomForestRegressor metrics with corrected parsing\"\"\"\n",
    "    if 'PoissonRandomForestRegressor' not in content:\n",
    "        return None\n",
    "    \n",
    "    model_data = {\n",
    "        'unique_id': unique_id,\n",
    "        'n': n,\n",
    "        'pi1': pi1,\n",
    "        'pi2': pi2,\n",
    "        'model': 'PoissonRandomForestRegressor',\n",
    "        'file': filename\n",
    "    }\n",
    "    \n",
    "    # Extract PoissonRandomForestRegressor section\n",
    "    prf_section = re.search(r'PoissonRandomForestRegressor.*?------------------------------(.*?)(?=------------------------------|$)', content, re.DOTALL)\n",
    "    if prf_section:\n",
    "        section_content = prf_section.group(1)\n",
    "        \n",
    "        # Rate predictions\n",
    "        rate_match = re.search(r'Rate predictions.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?R²:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if rate_match:\n",
    "            model_data['rate_MSE'] = float(rate_match.group(1))\n",
    "            model_data['rate_MAE'] = float(rate_match.group(2))\n",
    "            model_data['rate_R2'] = float(rate_match.group(3))\n",
    "        \n",
    "        # Count predictions\n",
    "        count_match = re.search(r'Count predictions.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?R²:\\s*([\\d.-]+).*?Accuracy:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if count_match:\n",
    "            model_data['count_MSE'] = float(count_match.group(1))\n",
    "            model_data['count_MAE'] = float(count_match.group(2))\n",
    "            model_data['count_R2'] = float(count_match.group(3))\n",
    "            model_data['count_Accuracy'] = float(count_match.group(4))\n",
    "    \n",
    "    return model_data\n",
    "\n",
    "def extract_metric_specific(text, metric_name):\n",
    "    \"\"\"Extract a specific metric from text with better precision\"\"\"\n",
    "    pattern = rf'{metric_name}:\\s*([\\d.-]+)'\n",
    "    match = re.search(pattern, text)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parse_targeted_files_corrected()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
