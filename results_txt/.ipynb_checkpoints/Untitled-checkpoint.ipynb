{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b52b1ef-4ead-4003-84cd-bed87e4470aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results_txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 235\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 235\u001b[0m     \u001b[43mparse_targeted_files_corrected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [15], line 10\u001b[0m, in \u001b[0;36mparse_targeted_files_corrected\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m all_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Look for files with your naming pattern\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../results_txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(x \u001b[38;5;129;01min\u001b[39;00m filename \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn=\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpi1=\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpi2=\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.log\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results_txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def parse_targeted_files_corrected():\n",
    "    \"\"\"Corrected parser with accurate metric extraction\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # Look for files with your naming pattern\n",
    "    for filename in os.listdir('../results_txt'):\n",
    "        if any(x in filename for x in ['n=', 'pi1=', 'pi2=']) or filename.endswith('.log'):\n",
    "            try:\n",
    "                with open(filename, 'r') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                # Extract parameters\n",
    "                n = re.search(r'n=(\\d+)', content)\n",
    "                pi1 = re.search(r'pi1=([\\d.]+)', content)\n",
    "                pi2 = re.search(r'pi2=([\\d.]+)', content)\n",
    "                \n",
    "                if n and pi1 and pi2:\n",
    "                    unique_id = f\"n={n.group(1)}_pi1={pi1.group(1)}_pi2={pi2.group(1)}\"\n",
    "                    \n",
    "                    # Parse metrics for each model\n",
    "                    models_data = parse_all_models_corrected(content, unique_id, n.group(1), pi1.group(1), pi2.group(1), filename)\n",
    "                    all_results.extend(models_data)\n",
    "                    \n",
    "                    print(f\"Processed: {filename}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error with {filename}: {e}\")\n",
    "    \n",
    "    # Create and save summary\n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Reorder columns for better readability\n",
    "        column_order = ['unique_id', 'n', 'pi1', 'pi2', 'model', 'file', \n",
    "                       'rate_MSE', 'rate_MAE', 'rate_R2',\n",
    "                       'count_MSE', 'count_MAE', 'count_R2', 'count_Accuracy']\n",
    "        \n",
    "        # Only include columns that actually exist in the data\n",
    "        final_columns = [col for col in column_order if col in df.columns]\n",
    "        df = df[final_columns]\n",
    "        \n",
    "        df.to_csv('summary.csv', index=False)\n",
    "        print(f\"\\nSaved summary with {len(all_results)} model entries to summary.csv\")\n",
    "        \n",
    "        # Display sample to verify no duplicates\n",
    "        print(\"\\nSample verification (showing first 2 experiments):\")\n",
    "        sample_df = df[df['unique_id'].isin(df['unique_id'].unique()[:2])]\n",
    "        print(sample_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No files processed!\")\n",
    "\n",
    "def parse_all_models_corrected(content, unique_id, n, pi1, pi2, filename):\n",
    "    \"\"\"Parse metrics for all models with corrected parsing\"\"\"\n",
    "    models_data = []\n",
    "    \n",
    "    # Parse ZKIPModel_EM\n",
    "    zkip_data = parse_zkp_model_corrected(content, unique_id, n, pi1, pi2, filename)\n",
    "    if zkip_data:\n",
    "        models_data.append(zkip_data)\n",
    "    \n",
    "    # Parse ZkICMP\n",
    "    zkicmp_data = parse_zkicmp_model_corrected(content, unique_id, n, pi1, pi2, filename)\n",
    "    if zkicmp_data:\n",
    "        models_data.append(zkicmp_data)\n",
    "    \n",
    "    # Parse HistGradientBoostingRegressor\n",
    "    hgb_data = parse_hgb_model_corrected(content, unique_id, n, pi1, pi2, filename)\n",
    "    if hgb_data:\n",
    "        models_data.append(hgb_data)\n",
    "    \n",
    "    # Parse PoissonRandomForestRegressor\n",
    "    prf_data = parse_prf_model_corrected(content, unique_id, n, pi1, pi2, filename)\n",
    "    if prf_data:\n",
    "        models_data.append(prf_data)\n",
    "    \n",
    "    return models_data\n",
    "\n",
    "def parse_zkp_model_corrected(content, unique_id, n, pi1, pi2, filename):\n",
    "    \"\"\"Parse ZKIPModel_EM metrics with corrected parsing\"\"\"\n",
    "    if 'ZKIPModel_EM' not in content:\n",
    "        return None\n",
    "    \n",
    "    model_data = {\n",
    "        'unique_id': unique_id,\n",
    "        'n': n,\n",
    "        'pi1': pi1,\n",
    "        'pi2': pi2,\n",
    "        'model': 'ZKIPModel_EM',\n",
    "        'file': filename\n",
    "    }\n",
    "    \n",
    "    # Extract ZKIPModel_EM section\n",
    "    zkip_section = re.search(r'ZKIPModel_EM.*?------------------------------(.*?)(?=------------------------------|$)', content, re.DOTALL)\n",
    "    if zkip_section:\n",
    "        section_content = zkip_section.group(1)\n",
    "        \n",
    "        # Expected value predictions\n",
    "        expected_section = re.search(r'Expected value prediction:(.*?)Mode prediction:', section_content, re.DOTALL)\n",
    "        if expected_section:\n",
    "            expected_text = expected_section.group(1)\n",
    "            model_data['rate_MSE'] = extract_metric_specific(expected_text, 'MSE')\n",
    "            model_data['rate_MAE'] = extract_metric_specific(expected_text, 'MAE')\n",
    "            model_data['rate_R2'] = extract_metric_specific(expected_text, 'r\\^2')\n",
    "        \n",
    "        # Mode predictions\n",
    "        mode_section = re.search(r'Mode prediction:(.*?)(?=Performance metrics:|$)', section_content, re.DOTALL)\n",
    "        if mode_section:\n",
    "            mode_text = mode_section.group(1)\n",
    "            model_data['count_MSE'] = extract_metric_specific(mode_text, 'MSE')\n",
    "            model_data['count_MAE'] = extract_metric_specific(mode_text, 'MAE')\n",
    "            model_data['count_R2'] = extract_metric_specific(mode_text, 'r\\^2')\n",
    "            model_data['count_Accuracy'] = extract_metric_specific(mode_text, 'Accuracy')\n",
    "    \n",
    "    return model_data\n",
    "\n",
    "def parse_zkicmp_model_corrected(content, unique_id, n, pi1, pi2, filename):\n",
    "    \"\"\"Parse ZkICMP metrics with corrected parsing\"\"\"\n",
    "    if 'ZkICMP' not in content:\n",
    "        return None\n",
    "    \n",
    "    model_data = {\n",
    "        'unique_id': unique_id,\n",
    "        'n': n,\n",
    "        'pi1': pi1,\n",
    "        'pi2': pi2,\n",
    "        'model': 'ZkICMP',\n",
    "        'file': filename\n",
    "    }\n",
    "    \n",
    "    # Extract ZkICMP section\n",
    "    zkicmp_section = re.search(r'ZkICMP.*?------------------------------(.*?)(?=------------------------------|$)', content, re.DOTALL)\n",
    "    if zkicmp_section:\n",
    "        section_content = zkicmp_section.group(1)\n",
    "        \n",
    "        # Rate predictions\n",
    "        rate_match = re.search(r'Rate predictions.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?r\\^2:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if rate_match:\n",
    "            model_data['rate_MSE'] = float(rate_match.group(1))\n",
    "            model_data['rate_MAE'] = float(rate_match.group(2))\n",
    "            model_data['rate_R2'] = float(rate_match.group(3))\n",
    "        \n",
    "        # Count predictions\n",
    "        count_match = re.search(r'Count predictions:.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?r\\^2:\\s*([\\d.-]+).*?Accuracy:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if count_match:\n",
    "            model_data['count_MSE'] = float(count_match.group(1))\n",
    "            model_data['count_MAE'] = float(count_match.group(2))\n",
    "            model_data['count_R2'] = float(count_match.group(3))\n",
    "            model_data['count_Accuracy'] = float(count_match.group(4))\n",
    "    \n",
    "    return model_data\n",
    "\n",
    "def parse_hgb_model_corrected(content, unique_id, n, pi1, pi2, filename):\n",
    "    \"\"\"Parse HistGradientBoostingRegressor metrics with corrected parsing\"\"\"\n",
    "    if 'HistGradientBoostingRegressor' not in content:\n",
    "        return None\n",
    "    \n",
    "    model_data = {\n",
    "        'unique_id': unique_id,\n",
    "        'n': n,\n",
    "        'pi1': pi1,\n",
    "        'pi2': pi2,\n",
    "        'model': 'HistGradientBoostingRegressor',\n",
    "        'file': filename\n",
    "    }\n",
    "    \n",
    "    # Extract HistGradientBoostingRegressor section\n",
    "    hgb_section = re.search(r'HistGradientBoostingRegressor.*?------------------------------(.*?)(?=------------------------------|$)', content, re.DOTALL)\n",
    "    if hgb_section:\n",
    "        section_content = hgb_section.group(1)\n",
    "        \n",
    "        # Rate predictions\n",
    "        rate_match = re.search(r'Rate predictions.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?R²:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if rate_match:\n",
    "            model_data['rate_MSE'] = float(rate_match.group(1))\n",
    "            model_data['rate_MAE'] = float(rate_match.group(2))\n",
    "            model_data['rate_R2'] = float(rate_match.group(3))\n",
    "        \n",
    "        # Count predictions\n",
    "        count_match = re.search(r'Count predictions.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?R²:\\s*([\\d.-]+).*?Accuracy:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if count_match:\n",
    "            model_data['count_MSE'] = float(count_match.group(1))\n",
    "            model_data['count_MAE'] = float(count_match.group(2))\n",
    "            model_data['count_R2'] = float(count_match.group(3))\n",
    "            model_data['count_Accuracy'] = float(count_match.group(4))\n",
    "    \n",
    "    return model_data\n",
    "\n",
    "def parse_prf_model_corrected(content, unique_id, n, pi1, pi2, filename):\n",
    "    \"\"\"Parse PoissonRandomForestRegressor metrics with corrected parsing\"\"\"\n",
    "    if 'PoissonRandomForestRegressor' not in content:\n",
    "        return None\n",
    "    \n",
    "    model_data = {\n",
    "        'unique_id': unique_id,\n",
    "        'n': n,\n",
    "        'pi1': pi1,\n",
    "        'pi2': pi2,\n",
    "        'model': 'PoissonRandomForestRegressor',\n",
    "        'file': filename\n",
    "    }\n",
    "    \n",
    "    # Extract PoissonRandomForestRegressor section\n",
    "    prf_section = re.search(r'PoissonRandomForestRegressor.*?------------------------------(.*?)(?=------------------------------|$)', content, re.DOTALL)\n",
    "    if prf_section:\n",
    "        section_content = prf_section.group(1)\n",
    "        \n",
    "        # Rate predictions\n",
    "        rate_match = re.search(r'Rate predictions.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?R²:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if rate_match:\n",
    "            model_data['rate_MSE'] = float(rate_match.group(1))\n",
    "            model_data['rate_MAE'] = float(rate_match.group(2))\n",
    "            model_data['rate_R2'] = float(rate_match.group(3))\n",
    "        \n",
    "        # Count predictions\n",
    "        count_match = re.search(r'Count predictions.*?MSE:\\s*([\\d.-]+).*?MAE:\\s*([\\d.-]+).*?R²:\\s*([\\d.-]+).*?Accuracy:\\s*([\\d.-]+)', section_content, re.DOTALL)\n",
    "        if count_match:\n",
    "            model_data['count_MSE'] = float(count_match.group(1))\n",
    "            model_data['count_MAE'] = float(count_match.group(2))\n",
    "            model_data['count_R2'] = float(count_match.group(3))\n",
    "            model_data['count_Accuracy'] = float(count_match.group(4))\n",
    "    \n",
    "    return model_data\n",
    "\n",
    "def extract_metric_specific(text, metric_name):\n",
    "    \"\"\"Extract a specific metric from text with better precision\"\"\"\n",
    "    pattern = rf'{metric_name}:\\s*([\\d.-]+)'\n",
    "    match = re.search(pattern, text)\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parse_targeted_files_corrected()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
